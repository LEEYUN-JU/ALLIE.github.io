---
layout: post
title: A Weakly Supervised Amodal Segmenter with Boundary Uncertainty Estimation
comments: true
categories : [paper]
published: true

---

## Introduction
이 논문의 intro 에서는 왜 amodal instance segmentation이 중요한지, 어디에 사용되는지에 대해서 적어 놓았다. 대표적으로 사용되는 부분은 두 군데라고 한다. 첫째로는 자동차의 자율주행에 사용되는데, 차 뒤에 사람이 가려져 있는 경우라던가, 사고를 예방하기 위한 차원에서 사용된다고 한다. 두 번째로는 협동로봇이나, 로봇에 관한 경우이다. 로봇의 경우에는 경로를 설정해주고 그에 따른 목적을 달성하는것이 중요한데, 이때 장애물이 존재하는 경우에 장애물을 인식하여 경로를 설정하는 것이 매우 중요하다고 한다. 목표물이 가려져 있는 경우에 그 목표물을 찾고 타겟을 설정하여 그 타겟까지의 경로를 설정해 주어야 하기 때문이다. 

다음 그림은 이 논문의 contribution을 설명한 그림이다.
![enter image description here](https://ifh.cc/g/ZmORgS.jpg =750x)
이 그림에서 주목해야 할 곳은 주황색 박스와 하늘색 박스에 존재한다. 
> 1. 물체의 occlusion된 부분의 경계선을 사용한다는 것.
> 2. uncertainty 한 부분에 weighted loss 값을 추가로 지정해 준다는 것.

이 두 가지가 본 논문의 핵심이다.

## Realted Works
#### Instance Segmentation
관련 연구로는 Instance Segmentation에 대한 내용이 나온다. 가볍게 Instance Segmentation 에 관한 걸 설명하고, 그 다음으로는 Amodal instance segmentation 이 무엇인지에 대해서 설명한다. Instance Segmentation 은 말 그대로 같은 class에 속한 obejct 를 객체 별로 분류해 내는 것을 말한다. Amodal의 경우에는 겹쳐진 object 의 경계선을 찾아내어 객체별로 분류하는 것을 말한다.

#### Amodal Instance Completion

![enter image description here](https://ifh.cc/g/8mXysQ.png =700x)

Amodal Instance Completion의 경우는 다음과 같다. Amodal 된 부분을 얼마나 정답에 가깝게 맞추는 지에 대한 것을 말한다. 가령, 첫번째에 그려진 점선의 경우는 네모를 정확하게 표현한다. 하지만, 두 번재 세 번째 같은 그림의 네모는 현실적으로 존재한다고 보기 힘들다. 이러한 관점에서 사람은 당연스럽게 1번을 떠올릴 것이고, 이를 amodal instance completion이라고 한다.

#### WAIS (Weakly-supervised Amodal Instance Segmentation)

본 논문에 영감을 준 논문이라고 한다. 이 논문에서는 modal mask annotation 을 pseudo amodal mask 로 변경했다고 한다. 뿐만 아니라, self-supervised 를 사용하여, training data를 스스로 만들어 사용한다고 한다. 이것이 WAIS의 가장 큰 특징이다.

#### U-Net (Uncertainty Estimation in Segmentation)

U-Net 은 본디 바이오 메디칼 분야에서 처음 등장했다고 한다. 바이오 메디컬 분야에서, 세포들의 경계선을 찾아내는 것이 결과에 중요한 영향을 끼치기 때문에 경계선을 찾아는 것 (=segmentation)이 중요하다고 한다. U-Net에서 중요한 부분을 두 가지 찾아보자면, 
> Overlap-Tile Input
> Touching cells separation
 
 이 두 가지로 볼 수 있다. Overlap-tile의 경우, 입력 이미지의 경계선에 존재하는 부분을 mirror 처럼 반사 시켜, 패딩 하는 경우에 0패딩을 사용하는 것이 아니라 원본 이미지의 반전된 이미지를 사용하는(?) 방법이라고 한다. 
 ![enter image description here](https://ifh.cc/g/ajJrfw.jpg  =450x)

그 다음으로는 Touching cells separation 이 있다. 아까 언급한 같은 종류로 분류된 cell일지라도 경계를 잘 찾아내는 것이 중요한데, 그 부분에 관한 내용이다. 각 cell의 테두리를 분류해 내는 것을 말한다.

U-Net 은 Expanding Path 그리고 Contracting Path로 분류된다. Expanding Path의 경우 정확한 Localization 을 하고, feature map을 뽑아내기 위한 부분이라고 한다. Contracting Path 의 경우, input images에서 문맥을 뽑아내기 위한 부분이라고 한다. 

## Approach
![enter image description here](https://ifh.cc/g/TVfW3D.jpg =800x)

Approach 부분에서는 정확히 어떠한 경위로 실험 데이터를 구성하고 실험을 진행하는 지에 대한 내용이 적혀져 있다. 우선 모델을 학습시키는 데, occlusion boundary 정보가 사용된다. 여기서 원본 이미지 = 가려질 대상 = occludee 라고 하고, 가리는 물체 = 방해물 = occluder 라고 한다. occludee 위에 임의의 occluder를 self-supervised로 데이터를 생성한다. 그리고 그 경계선 정보를 얻게 된다. 이를 토대로 U-Net 으로 학습하여 불확실한 부분에 대한 값을 얻어낸다. 위와 같은 방식으로 학습 데이터를 구성하고 학습한다.

## Uncertainty Weighted Segmentation Loss

![enter image description here](https://ifh.cc/g/mhhYSm.png =800x)

Predciton 된 부분에 관해서는 Sigmoid 함수를 이용하고 Uncertain 부분에 대해서는 Soft-plus functoin 을 사용한다. Soft plus 함수는 매끄럽게 만든 ReLU함수 정도로 생각하면 되고, 식은 log(1+exp(z)) 이다. 

이 Loss 값의 목적은 총 두 개이다.
> 1. Uncertain 부분을 최대한 적게 하는 것. > 선이 얇으면 얇을수록 더 정확한 경계가 된다는 의미 정도로 받아들이면 될 것 같다.
> 2. 정답과 예측 값의 차이를 최대한 줄이는 것.

![enter image description here](https://ifh.cc/g/bQDddo.png =800x)

(1) 번 식은 정답과 예측값의 차이를 최대한 줄여주기 위한 Loss값이라고 보면 된다.
(2) 번 식은 Uncertainty Map 을 정규화 시키고 영역을 최대한 줄이기 위한 Loss 값이라고 보면 된다.

## Results
![enter image description here](https://ifh.cc/g/lLbmVx.jpg =800x)

평가 방법은 mIOU를 사용하였고, 관련 데이터 셋에 한해서 SOTA를 달성하였다. 
Contribution 1 이 Contribution 2 보다 정확도를 높이는데 더 기여하였다.
